# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md

build:
  # set to true if your model requires a GPU
  gpu: true
  cuda: "12.1"

  pre_install:
    - export PYTHON_CONFIGURE_OPTS=""
    - export CFLAGS=""
    - apt-get update -qq
    - apt-get install -qqy --no-install-recommends --fix-missing --allow-downgrades --force-yes python3-pip python3-setuptools

  # a list of ubuntu apt packages to install
  system_packages:
    - "aria2"
    - "ffmpeg"

  # python version in the form '3.8' or '3.8.12'
  python_version: "3.10"

  # a list of packages in the format <package-name>==<version>
  python_requirements: requirements.txt

  # commands run after the environment is setup
  run:
    - pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers
    - pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip
    - pip install diffusers
    - pip install --upgrade --no-cache-dir gdown
    - mkdir /stable-diffusion-checkpoints
    # if v1-5-pruned-emaonly.ckpt is not available, I have it somewhere
    - cd /stable-diffusion-checkpoints && wget https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt
    - pip install notebook
    - git clone https://github.com/CompVis/taming-transformers
    - git clone https://github.com/openai/CLIP
    - git clone https://github.com/crowsonkb/k-diffusion
    - pip install jsonmerge clean-fid resize-right torchdiffeq
    - pip install googletrans==3.1.0a0 librosa
    # xformers
    - pip install triton==2.1.0
    - pip install ninja
    - git clone https://github.com/facebookresearch/xformers.git
    - export FORCE_CUDA="1" && export CUDA_VISIBLE_DEVICES=0 && export TORCH_CUDA_ARCH_LIST=8.0 && export CUDA_HOME=/usr/local/cuda-12.1 && cd xformers && git submodule update --init --recursive && pip install -r requirements.txt && pip install -e .

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
